# ğŸ¤– LangChain + Azure OpenAIë¡œ Assistant ê¸°ëŠ¥ êµ¬í˜„í•˜ê¸°
# Assistant APIê°€ ì•„ë‹Œ ì¼ë°˜ Chat APIë¡œ Assistantì™€ ìœ ì‚¬í•œ ê¸°ëŠ¥ êµ¬í˜„

import os
import time
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_chroma import Chroma
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.schema import HumanMessage, SystemMessage
from dotenv import load_dotenv

load_dotenv()

class PDFAssistant:
    """PDF ê²€ìƒ‰ ì „ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸"""
    
    def __init__(self):
        print("ğŸ¤– PDF Assistantë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
        
        # Azure OpenAI ì„¤ì •
        self.llm = AzureChatOpenAI(
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            azure_deployment=os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT", "gpt-4"),
            openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            temperature=0.7
        )
        
        # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        self.embeddings = AzureOpenAIEmbeddings(
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            azure_deployment=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT"),
            openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        )
        
        # ëŒ€í™” ê¸°ì–µ ì¥ì¹˜ (Assistantì˜ ìƒíƒœ ìœ ì§€ ê¸°ëŠ¥)
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key='answer'
        )
        
        # ë²¡í„° ì €ì¥ì†Œì™€ ëŒ€í™” ì²´ì¸ (ë‚˜ì¤‘ì— ì´ˆê¸°í™”)
        self.vectorstore = None
        self.conversation_chain = None
        
        print("âœ… PDF Assistant ì¤€ë¹„ ì™„ë£Œ!")
    
    def load_pdf_knowledge(self, pdf_path="testpdf.pdf"):
        """PDFë¥¼ ì½ì–´ì„œ Assistantì˜ ì§€ì‹ìœ¼ë¡œ ë§Œë“¤ê¸°"""
        
        print(f"ğŸ“– PDF íŒŒì¼ ë¡œë”© ì¤‘: {pdf_path}")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(pdf_path):
            print(f"âŒ PDF íŒŒì¼ '{pdf_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        try:
            # 1. PDF ë¡œë“œ
            loader = PyPDFLoader(pdf_path)
            pages = loader.load()
            print(f"ğŸ“„ ì´ {len(pages)}í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
            
            # 2. í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = CharacterTextSplitter(
                separator="\n\n",
                chunk_size=1000,
                chunk_overlap=200,
                length_function=len,
            )
            texts = text_splitter.split_documents(pages)
            print(f"âœ‚ï¸ {len(texts)}ê°œ í…ìŠ¤íŠ¸ ì¡°ê°ìœ¼ë¡œ ë¶„í•  ì™„ë£Œ")
            
            # 3. ë²¡í„° ì €ì¥ì†Œ ìƒì„±
            print("ğŸ§  AIê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜ ì¤‘...")
            self.vectorstore = Chroma.from_documents(
                documents=texts,
                embedding=self.embeddings,
                persist_directory="./chroma_db"
            )
            
            # 4. ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸ ìƒì„± (Assistantì˜ í•µì‹¬ ê¸°ëŠ¥)
            self.conversation_chain = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
                memory=self.memory,
                return_source_documents=True,
                chain_type="stuff"
            )
            
            print("âœ… PDF ì§€ì‹ ë¡œë”© ì™„ë£Œ! ì´ì œ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âŒ PDF ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def chat(self, user_message):
        """ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ê¸° (Assistantì˜ í•µì‹¬ ê¸°ëŠ¥)"""
        
        if not self.conversation_chain:
            return "ë¨¼ì € PDFë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”! load_pdf_knowledge() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
        
        try:
            print(f"ğŸ¤” ì‚¬ìš©ì ì§ˆë¬¸: {user_message}")
            print("ğŸ’­ ë‹µë³€ì„ ìƒê°í•˜ëŠ” ì¤‘...")
            
            # ëŒ€í™”í˜• ê²€ìƒ‰ ì‹¤í–‰
            response = self.conversation_chain.invoke({"question": user_message})
            
            # ë‹µë³€ê³¼ ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
            answer = response['answer']
            source_docs = response.get('source_documents', [])
            
            # ì¶œì²˜ ì •ë³´ ì¶”ê°€
            if source_docs:
                sources = []
                for i, doc in enumerate(source_docs[:2], 1):  # ìƒìœ„ 2ê°œ ì¶œì²˜ë§Œ
                    page = doc.metadata.get('page', 'Unknown')
                    sources.append(f"í˜ì´ì§€ {page + 1}")
                
                answer += f"\n\nğŸ“š ì¶œì²˜: {', '.join(sources)}"
            
            return answer
            
        except Exception as e:
            return f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
    
    def get_chat_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ (Assistantì˜ ë©”ëª¨ë¦¬ ê¸°ëŠ¥)"""
        return self.memory.chat_memory.messages
    
    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.memory.clear()
        print("ğŸ—‘ï¸ ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ PDF Assistant ë°ëª¨ ì‹œì‘!")
    print("=" * 50)
    
    # 1. Assistant ìƒì„±
    assistant = PDFAssistant()
    
    # 2. PDF ì§€ì‹ ë¡œë“œ
    if not assistant.load_pdf_knowledge("testpdf.pdf"):
        print("PDF ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    print("\n" + "=" * 50)
    print("ğŸ’¬ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤! ('quit' ì…ë ¥ì‹œ ì¢…ë£Œ)")
    print("=" * 50)
    
    # 3. ëŒ€í™” ë£¨í”„
    while True:
        try:
            user_input = input("\nğŸ™‹ ì§ˆë¬¸: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤!")
                break
            
            if user_input.lower() == 'history':
                print("\nğŸ“œ ëŒ€í™” íˆìŠ¤í† ë¦¬:")
                for msg in assistant.get_chat_history():
                    role = "ì‚¬ìš©ì" if msg.type == "human" else "ì–´ì‹œìŠ¤í„´íŠ¸"
                    print(f"{role}: {msg.content[:100]}...")
                continue
            
            if user_input.lower() == 'clear':
                assistant.clear_history()
                continue
            
            if not user_input:
                print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
                continue
            
            # Assistantì™€ ëŒ€í™”
            response = assistant.chat(user_input)
            print(f"\nğŸ¤– Assistant: {response}")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤!")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
