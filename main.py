import os
import sys
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI
from langchain_core.messages import HumanMessage
import streamlit as st

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Azure OpenAI ì„¤ì •ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ë“¤
# .env íŒŒì¼ì— ë‹¤ìŒ ë³€ìˆ˜ë“¤ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:
# AZURE_OPENAI_API_KEY=your_api_key
# AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
# AZURE_OPENAI_API_VERSION=2023-12-01-preview
# AZURE_OPENAI_CHAT_DEPLOYMENT=your-deployment-name

# Chat ëª¨ë¸ (ëŒ€í™”ìš© - gpt-4oëŠ” chat ëª¨ë¸ë§Œ ì§€ì›)
@st.cache_resource
def get_chat_model():
    return AzureChatOpenAI(
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
        deployment_name=os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT"),
        temperature=0.7,
        max_tokens=1000
    )

def chat_with_ai(user_input):
    """ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ì„œ AI ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    try:
        chat_model = get_chat_model()
        message = HumanMessage(content=user_input)
        response = chat_model.invoke([message])
        return response.content
    except Exception as e:
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# Streamlit ì›¹ ì•±
st.title("ğŸ¤– Azure OpenAI ëŒ€í™” ì•±")
st.markdown(f"**ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸:** {os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT')}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ì €ì¥ìš©)
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘..."):
            response = chat_with_ai(prompt)
        st.markdown(response)
    
    # AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": response})
# ì‚¬ì´ë“œë°”ì— ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
with st.sidebar:
    st.header("ì˜µì…˜")
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

